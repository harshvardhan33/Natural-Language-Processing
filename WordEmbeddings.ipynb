{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordEmbeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Res278_nu3LP"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "sent=[  'the glass of milk',\r\n",
        "     'the glass of juice',\r\n",
        "     'the cup of tea',\r\n",
        "    'I am a good boy',\r\n",
        "     'I am a good developer',\r\n",
        "     'understand the meaning of words',\r\n",
        "     'your videos are good']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0novdV6KvhS8"
      },
      "source": [
        "1. We should fix a vocaubulary size that will help us in representation.\r\n",
        "\r\n",
        "2. Based on vocabulary size, we can one hote encode the words of the sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr_TK0fDvDpb",
        "outputId": "3314e35e-849e-412b-c0d8-e04e33f8c3a8"
      },
      "source": [
        "voc_size = 100\r\n",
        "onehot_repr=[one_hot(words,voc_size)for words in sent] \r\n",
        "print(onehot_repr)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[13, 71, 71, 14], [13, 71, 71, 5], [13, 56, 71, 7], [3, 30, 3, 86, 14], [3, 30, 3, 86, 26], [97, 13, 50, 71, 77], [24, 14, 45, 86]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N74YJ6DPvxmS"
      },
      "source": [
        "1. For implementation of embedding matrix in keras layers we need to have a size of the embedding layer also known as dimension.\r\n",
        "\r\n",
        "2. What actually is embedding layer doing?<br>\r\n",
        "It is feature representation, lets say i have a word BOY, and my embedding dimension is 10. So the vector representing the word boy will have the size equals to 10. So if a sentence is having 8 number of words, and emdedding dimension is said to be 10.\r\n",
        "The embedding matrix for that sentence will be equal to (8,10).\r\n",
        "For each word in the sentence from 0....7 ,I will have a vector of dimemnsion 10.\r\n",
        "3. Another thing that we need to take care about is padding, so all sentences are not of same length, so what we can do is we can have a fixed sentence length that will pad the sentences when they are smaller from the desired size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP2sbs_BvNyf",
        "outputId": "9ae1a6c5-0a0d-4858-a3cf-d92b6aa59f16"
      },
      "source": [
        " from tensorflow.keras.layers import Embedding\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "\r\n",
        "\r\n",
        "sent_length=8\r\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\r\n",
        "print(embedded_docs)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0 13 71 71 14]\n",
            " [ 0  0  0  0 13 71 71  5]\n",
            " [ 0  0  0  0 13 56 71  7]\n",
            " [ 0  0  0  3 30  3 86 14]\n",
            " [ 0  0  0  3 30  3 86 26]\n",
            " [ 0  0  0 97 13 50 71 77]\n",
            " [ 0  0  0  0 24 14 45 86]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf9m9JJ-wefV"
      },
      "source": [
        "# Dimension for each feature \r\n",
        "\r\n",
        "dim=10\r\n",
        "model=Sequential()\r\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\r\n",
        "model.compile('adam','mse')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSD36rV8w-Tw",
        "outputId": "a9a30485-87cf-400b-806a-868d38a29cc6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 8, 10)             100000    \n",
            "=================================================================\n",
            "Total params: 100,000\n",
            "Trainable params: 100,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4O434dMxy6A",
        "outputId": "daea5181-c655-4499-b60f-f8e3d5c32b78"
      },
      "source": [
        "print(model.predict(embedded_docs)[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.03496313  0.04286364  0.02410268 -0.02876645  0.01484202 -0.01748316\n",
            "  -0.04163278 -0.04111578 -0.00385138  0.045369  ]\n",
            " [ 0.03496313  0.04286364  0.02410268 -0.02876645  0.01484202 -0.01748316\n",
            "  -0.04163278 -0.04111578 -0.00385138  0.045369  ]\n",
            " [ 0.03496313  0.04286364  0.02410268 -0.02876645  0.01484202 -0.01748316\n",
            "  -0.04163278 -0.04111578 -0.00385138  0.045369  ]\n",
            " [ 0.03496313  0.04286364  0.02410268 -0.02876645  0.01484202 -0.01748316\n",
            "  -0.04163278 -0.04111578 -0.00385138  0.045369  ]\n",
            " [-0.01617346 -0.00043703  0.02660931  0.04483845 -0.018908   -0.01193035\n",
            "  -0.0393031   0.00770854  0.01298909  0.03455018]\n",
            " [ 0.00967842  0.02840439 -0.03080238  0.02907977  0.00583106  0.01440724\n",
            "   0.03723377 -0.04170398 -0.028197   -0.02958464]\n",
            " [ 0.00967842  0.02840439 -0.03080238  0.02907977  0.00583106  0.01440724\n",
            "   0.03723377 -0.04170398 -0.028197   -0.02958464]\n",
            " [-0.02699585  0.01594957  0.01017511 -0.04188485  0.02635803 -0.02835122\n",
            "   0.01018913 -0.03975717 -0.02353048 -0.04458045]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KGLblVDxdMN",
        "outputId": "95eb84ec-a667-4a4c-e9cf-6f7283ee89ce"
      },
      "source": [
        "print(model.predict(embedded_docs)[0].shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkliJNDkxpIz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}